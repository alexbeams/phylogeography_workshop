[
  {
    "objectID": "topics/sse_models/sim_sse.html",
    "href": "topics/sse_models/sim_sse.html",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "",
    "text": "rm(list=ls())\nlibrary(diversitree)\n\nState-dependent speciation and extion (SSE) models are the subject of this set of exercises. The workhorse of these methods are the various flavors of birth-death models for generating trees.\nSo far, we have been treating the trees as given without asking how they are created (by some biologist, presumably). If the traits we are interested in do not influence diversification, extinction/death, or the probability we observe a particular lineage, then the standard Markov models on trees seem sufficient. In some cases, traits might influence the process creating the phylogenetic relationships we observe, and we would like to detect these effects.\nIt is for this reason that we start by considering models for tree generation (sometimes called “tree priors” by people who use BEAST, which we will get to later in the week).\nLet’s start by simulating some trees using birth-death models.\n\ntree &lt;- tree.bd(c(lambda=1, mu=0), max.taxa = 50)\nplot(tree)\n\nNeat-o. But it doesn’t always work if mu&gt;0. Let’s use the lapply function to generate a list of simulated outputs (lapply is like a for loop, but more high-brow).\n\nnumtrees &lt;- 50\ntreelist &lt;- lapply(1:numtrees, \n        function(x) tree.bd(c(lambda=10, mu=5), max.taxa = 50)\n)\n\ndieoffs &lt;- sapply(treelist, is.null)\nnumdieoffs &lt;- sum(dieoffs)\n\nSometimes we fail to generate a tree with max.taxa number of lineages because they all go extinct (this is stochastic). Let’s see how many we were able to generate:"
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#learning-by-simulating",
    "href": "topics/sse_models/sim_sse.html#learning-by-simulating",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "",
    "text": "rm(list=ls())\nlibrary(diversitree)\n\nState-dependent speciation and extion (SSE) models are the subject of this set of exercises. The workhorse of these methods are the various flavors of birth-death models for generating trees.\nSo far, we have been treating the trees as given without asking how they are created (by some biologist, presumably). If the traits we are interested in do not influence diversification, extinction/death, or the probability we observe a particular lineage, then the standard Markov models on trees seem sufficient. In some cases, traits might influence the process creating the phylogenetic relationships we observe, and we would like to detect these effects.\nIt is for this reason that we start by considering models for tree generation (sometimes called “tree priors” by people who use BEAST, which we will get to later in the week).\nLet’s start by simulating some trees using birth-death models.\n\ntree &lt;- tree.bd(c(lambda=1, mu=0), max.taxa = 50)\nplot(tree)\n\nNeat-o. But it doesn’t always work if mu&gt;0. Let’s use the lapply function to generate a list of simulated outputs (lapply is like a for loop, but more high-brow).\n\nnumtrees &lt;- 50\ntreelist &lt;- lapply(1:numtrees, \n        function(x) tree.bd(c(lambda=10, mu=5), max.taxa = 50)\n)\n\ndieoffs &lt;- sapply(treelist, is.null)\nnumdieoffs &lt;- sum(dieoffs)\n\nSometimes we fail to generate a tree with max.taxa number of lineages because they all go extinct (this is stochastic). Let’s see how many we were able to generate:"
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section",
    "href": "topics/sse_models/sim_sse.html#section",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "1.",
    "text": "1.\nThe parameter “lambda” is the birth/diversification rate, and the parameter “mu” is the mortality/extinction rate. Try different combinations of the parameters (try lambda = 20, 50, 100, and mu = 20, 50, 100). What do you notice about your simulations? Hint: you should write a function called “getnumdieoffs” that accepts lambda, mu, and numtaxa, and then spits out treelist. Then you can create another function that acts on treelist to return numdieoffs. Organize the results of your simulations in a nice display."
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section-1",
    "href": "topics/sse_models/sim_sse.html#section-1",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "2.",
    "text": "2.\nTry to simulate trees with lambda = 1, mu = 2, and 10 taxa. How many simulations do you need to run until you start seeing trees with 10 taxa produced?"
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section-2",
    "href": "topics/sse_models/sim_sse.html#section-2",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "3.",
    "text": "3.\nUse ?trees to examine the help page for some of other tree simulation models. You will notcie tree.bd and tree.yule toward the bottom. Use your investigative abilities to research the Yule process and compare it to the birth- death process."
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section-3",
    "href": "topics/sse_models/sim_sse.html#section-3",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "4.",
    "text": "4.\nDo tree.yule(1, max.taxa=10) and tree.bd(lambda=2,mu=1, max.taxa=10) simulate the same process? Justify your answer."
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section-4",
    "href": "topics/sse_models/sim_sse.html#section-4",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "5.",
    "text": "5.\nDo tree.yule(1, max.taxa=10) and tree.bd(lambda=1,mu=0, max.taxa=10) simulate the same process? Justify your answer."
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section-5",
    "href": "topics/sse_models/sim_sse.html#section-5",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "6.",
    "text": "6.\nThe diversitree package can simulate tip data using Markov models for two discrete states initialized from a particular state at the root. One model is the “mk2” model: sim.character(tree, pars, x0=0, model=“mk2”, br=NULL) the “pars” argument is a vector of the form (q12,q21) corresponding to the transition rates of the stochastic rate matrix, Q (the model argument can also be set to “mkn” to simulate Markov models with n states). Compare sim.character with the simMk function from phytools. Confirm whether these two R functions simulate the same process."
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#bisse-simulation-exercises",
    "href": "topics/sse_models/sim_sse.html#bisse-simulation-exercises",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "BiSSE Simulation Exercises:",
    "text": "BiSSE Simulation Exercises:"
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section-6",
    "href": "topics/sse_models/sim_sse.html#section-6",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "1 .",
    "text": "1 .\nSimulate a population that starts in a hostile environment but can move to a safer habitat with less predation. Assume the organisms are dumb (or just plants), so that individuals tend to spend the same amount of time in each habitat before moving to the other one. Do the simulations match your intuition about what should happen to the population in this scenario? Do you see different outcomes if migration is slow or fast relative to the birth and death rates? What happens if you simulate more taxa? (Try up to 10^4 or 10^5)."
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section-7",
    "href": "topics/sse_models/sim_sse.html#section-7",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "2.",
    "text": "2.\nSimulate a population that can move to a new habitat where there are more resources available, and organisms can produce more offspring. Assume that organisms have the same life expectancy in each area. You can also assume that individuals spend the same amount of time in each location. How does this scenario compare to the previous one, in terms of the trees you generate? Try different numbers of taxa."
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section-8",
    "href": "topics/sse_models/sim_sse.html#section-8",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "3.",
    "text": "3.\nNow, suppose through no fault of their own that organisms are transported to a terrible environment at a much faster rate than they can escape. If you didn’t know the parameters you used, would it be obvious from the trees that one of the locations is worse than the the other?"
  },
  {
    "objectID": "topics/sse_models/sim_sse.html#section-9",
    "href": "topics/sse_models/sim_sse.html#section-9",
    "title": "Intro to State-dependent speciation and extinction (SSE) models",
    "section": "4.",
    "text": "4.\nSupose the organisms are intelligent, and preferentially move to the location where there is less predation, and/or better resources. Do the phylogenies contain information about the crummy habitat?"
  },
  {
    "objectID": "topics/ancestral_character_estimation/ace_sims.html",
    "href": "topics/ancestral_character_estimation/ace_sims.html",
    "title": "Fitting and simulating Markov models on trees using ancestral character estimation (ace)",
    "section": "",
    "text": "rm(list=ls())\n\nlibrary(ape)\nlibrary(expm) # matrix exponential\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'expm'\n\n\nThe following object is masked from 'package:Matrix':\n\n    expm\n\n\nThe following object is masked from 'package:ape':\n\n    balance\n\n\nThis code simulates output from the ace function. We will first try to grasp how the model behaves before we we try fitting it to data.\nAncestral character estimation methods can be based on a variety of approaches, but we will consider Markov chains superimposed on phylogenies. In the accompanying code to this we will learn how to fit these models using Maximum Likelihood, but for now we focus on simulating Markov chains on trees to understand how the models work.\nFirst, let’s simulate a tree and some tip states:\n\ntree &lt;- rcoal(10)\nx &lt;- sample(c(0,1), size=10, replace=T)\n\nplot(tree)\ntiplabels(pch=21,bg=x)\n\n\n\n\n\n\n\nfit &lt;- ace(x, tree, type='discrete', model='ARD')"
  },
  {
    "objectID": "topics/ancestral_character_estimation/ace_sims.html#section",
    "href": "topics/ancestral_character_estimation/ace_sims.html#section",
    "title": "Fitting and simulating Markov models on trees using ancestral character estimation (ace)",
    "section": "1.",
    "text": "1.\nSimulate some tip states on a tree using a Markov model that you specify, and use ace to estimate it. Scale this up for a large number of tip state configurations to see how the distribution of Maximum Likelihood estimates for the Markov model rates compare with the true values you supplied. Are there particular combinations of branch lengths and rates that make it difficult to estimate model parameters?"
  },
  {
    "objectID": "topics/ancestral_character_estimation/ace_sims.html#hard",
    "href": "topics/ancestral_character_estimation/ace_sims.html#hard",
    "title": "Fitting and simulating Markov models on trees using ancestral character estimation (ace)",
    "section": "2. (Hard)",
    "text": "2. (Hard)\nModify the code above to condition on a particular tip state configuration. This way, we can observe distributions of evolutionary scenarios consistent with a particular set of observations."
  },
  {
    "objectID": "topics/ancestral_character_estimation/ace_sims.html#section-1",
    "href": "topics/ancestral_character_estimation/ace_sims.html#section-1",
    "title": "Fitting and simulating Markov models on trees using ancestral character estimation (ace)",
    "section": "3.",
    "text": "3.\nIn a fitted ace object, there is an elemet called lik.anc which records the probability of ancestral states at each node of the tree. Plot a dataset of your choice with pie charts displaying the ancestral state probabilities associated with models that you fit using ace. Navigate through the help pages (?ace) to specify a few different versions of models that impose constraints on the Markov generator, Q. How sensitive are ancestral state probabilities to your modeling choices?"
  },
  {
    "objectID": "topics/character_mapping/fit_stochastic_mapping.html",
    "href": "topics/character_mapping/fit_stochastic_mapping.html",
    "title": "Exercise set 1:",
    "section": "",
    "text": "rm(list=ls())\nlibrary(coda) # for handling output from MCMC\nlibrary(phytools) # simmap functions, Mk models\n\nThis code is complementary to the other one in this subdirectory, and walks through how to fit models using a character mapping approach.\nMost of the phytools stuff is based on the Mk model, which is a particular type of Markov model. M stands for “Markov”, and “k” indicates the number of states. (Lewis has an interesting discussion relating to the use of conditional likelihoods as a means of overcoming acquisition bias – the tendency to only record changes of state, and not maintenance of a character).\nfitMk fits the model to the data using nlminb, and optimization routine similar to quasi- Newton methods like BFGS. Compare this to ace.\nmcmcMk fits Mk models to trees using MCMC.\n\ndata(sunfish.tree)\ndata(sunfish.data)\n\n# extract discrete character (fish diet):\nsunfish_tipdata &lt;-setNames(sunfish.data$feeding.mode,\n    rownames(sunfish.data))\n\n# fit \"ER\" model\nfit.ER&lt;-fitMk(sunfish.tree,sunfish_tipdata,model=\"ER\")\nprint(fit.ER)\n\nThis will run for a while, and you should see traceplots updating in real time until it finishes:\n\n    fit.mcmc &lt;- mcmcMk(sunfish.tree, sunfish_tipdata, \n    model=\"ER\", ngen=10000)\n\nThe dimensions of fit.mcmc will be ngen * (number of parameters in the Mk model + 2), which for this run will be 10000 x 3 because we are only estimating a single parameter\nThe first column of fit.mcmc is timesteps of the MCMC routine. The last column of fit.mcmc is the logLikelihood, and the columns between first and last are the parameters at each timestep.\nWe can look at the traceplots:\n\nplot(fit.mcmc)\n\nWe can also plot the posterior distribution for our parameters. By default, this should toss out the first 20% of the MCMC updates as part of a burn-in (we discard transients because we only care about the stationary distribution of the MCMC run)\n\nplot(density(fit.mcmc))\n\nOf note, we can also use base R plotting to accomplish these things as well. Here is a histogram of the parameter values of the entire MCMC run:\n\nhist(fit.mcmc[,'[pisc,non]'],breaks=100) \n\n# and the last 80% of the run:\nhist(fit.mcmc[c(2001:10000),'[pisc,non]'],breaks=100) \n\nI also like to plot profile log- likelihood (logLik~parameters):\n\nplot(fit.mcmc[,'logLik']~fit.mcmc[,'[pisc,non]'])\n\nThis helps us visualize the peak of the likelihood surface. Can be useful for diagnosing convergence problems."
  },
  {
    "objectID": "topics/character_mapping/fit_stochastic_mapping.html#fitting-markov-models-with-stochastic-character-mapping",
    "href": "topics/character_mapping/fit_stochastic_mapping.html#fitting-markov-models-with-stochastic-character-mapping",
    "title": "Exercise set 1:",
    "section": "",
    "text": "rm(list=ls())\nlibrary(coda) # for handling output from MCMC\nlibrary(phytools) # simmap functions, Mk models\n\nThis code is complementary to the other one in this subdirectory, and walks through how to fit models using a character mapping approach.\nMost of the phytools stuff is based on the Mk model, which is a particular type of Markov model. M stands for “Markov”, and “k” indicates the number of states. (Lewis has an interesting discussion relating to the use of conditional likelihoods as a means of overcoming acquisition bias – the tendency to only record changes of state, and not maintenance of a character).\nfitMk fits the model to the data using nlminb, and optimization routine similar to quasi- Newton methods like BFGS. Compare this to ace.\nmcmcMk fits Mk models to trees using MCMC.\n\ndata(sunfish.tree)\ndata(sunfish.data)\n\n# extract discrete character (fish diet):\nsunfish_tipdata &lt;-setNames(sunfish.data$feeding.mode,\n    rownames(sunfish.data))\n\n# fit \"ER\" model\nfit.ER&lt;-fitMk(sunfish.tree,sunfish_tipdata,model=\"ER\")\nprint(fit.ER)\n\nThis will run for a while, and you should see traceplots updating in real time until it finishes:\n\n    fit.mcmc &lt;- mcmcMk(sunfish.tree, sunfish_tipdata, \n    model=\"ER\", ngen=10000)\n\nThe dimensions of fit.mcmc will be ngen * (number of parameters in the Mk model + 2), which for this run will be 10000 x 3 because we are only estimating a single parameter\nThe first column of fit.mcmc is timesteps of the MCMC routine. The last column of fit.mcmc is the logLikelihood, and the columns between first and last are the parameters at each timestep.\nWe can look at the traceplots:\n\nplot(fit.mcmc)\n\nWe can also plot the posterior distribution for our parameters. By default, this should toss out the first 20% of the MCMC updates as part of a burn-in (we discard transients because we only care about the stationary distribution of the MCMC run)\n\nplot(density(fit.mcmc))\n\nOf note, we can also use base R plotting to accomplish these things as well. Here is a histogram of the parameter values of the entire MCMC run:\n\nhist(fit.mcmc[,'[pisc,non]'],breaks=100) \n\n# and the last 80% of the run:\nhist(fit.mcmc[c(2001:10000),'[pisc,non]'],breaks=100) \n\nI also like to plot profile log- likelihood (logLik~parameters):\n\nplot(fit.mcmc[,'logLik']~fit.mcmc[,'[pisc,non]'])\n\nThis helps us visualize the peak of the likelihood surface. Can be useful for diagnosing convergence problems."
  },
  {
    "objectID": "topics/character_mapping/fit_stochastic_mapping.html#section",
    "href": "topics/character_mapping/fit_stochastic_mapping.html#section",
    "title": "Exercise set 1:",
    "section": "1.",
    "text": "1.\nDid the fitMk routine produce the same estimates as mcmcMk? How would you determine this?"
  },
  {
    "objectID": "topics/character_mapping/fit_stochastic_mapping.html#section-6",
    "href": "topics/character_mapping/fit_stochastic_mapping.html#section-6",
    "title": "Exercise set 1:",
    "section": "1.",
    "text": "1.\nWhy do you think the mcmcMk routine does not propose character mappings alongside parameters? Would anything be gained by treating character mappings as latent variables in MCMC and updating those alongside parameters?\nCheck this paper out if you are interested in MCMC and character mapping:\nMutations as Missing Data: Inferences on the Ages and Distributions of Nonsynonymous and Synonymous Mutations, by Rasmus Nielsen Genetics 159: 401-411 (September 2001)"
  },
  {
    "objectID": "topics/character_mapping/fit_stochastic_mapping.html#section-7",
    "href": "topics/character_mapping/fit_stochastic_mapping.html#section-7",
    "title": "Exercise set 1:",
    "section": "2.",
    "text": "2.\nComment on any interesting things you see in profile loglikelihoods for models with multiple parameters. Can you deduce anything interesting about the geometry of the likelihood surface?"
  },
  {
    "objectID": "topics/character_mapping/fit_stochastic_mapping.html#section-8",
    "href": "topics/character_mapping/fit_stochastic_mapping.html#section-8",
    "title": "Exercise set 1:",
    "section": "3.",
    "text": "3.\nIn the previous runs, how did we estimate Pi, the probability of the root states? Examine the fitMk and mcmcMk help page to determine what the default is. Try fitting the model under a different setting to see how results change."
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About This Workshop",
    "section": "",
    "text": "This workshop is organized and hosted by MAGPIE.\nIt is focused toward our graduate students, but anybody with interests in mathematical biology, evolutionary biology, infectious diseases, and statistics is welcome to join!"
  },
  {
    "objectID": "about.html#instructors",
    "href": "about.html#instructors",
    "title": "About This Workshop",
    "section": "Instructors",
    "text": "Instructors\n\n\n\n\n\n\nInstructor One\nShort bio paragraph: background, expertise, and current role.\nOptional links: Personal Website, GitHub.\n\n\n\n\n\n\n\n\n\n\n\n\nInstructor Two\nShort bio paragraph: background, teaching areas, and research focus.\nOptional links: Personal Website."
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "MAGPIE PhylogeogRaphy Workshop (with BEAST 2)",
    "section": "",
    "text": "Sessions are split into roughly two-hour chunks that align with typical start/end times of classes, and are meant to be as self-contained as possible – so, feel free to come and go as necessary! All materials will posted here for you to catch up on content if desired.\nParticipants should bring their own laptops for hands-on exercises.\nFor specific requirements, see the individual session pages.\n\n\n\nMonday[September 29, 2025]\n\n\n\n\n\n0930–1130: Introduction to Phylogenies and Markov models\n\nShort description\n\n\n\n\n\n\n\n\n1130–1430: Basic models for ancestral character estimation\n\nShort description\n\n\n\n::: :::\n\n\n\n\n1430–1630: Stochastic character mapping\n\nShort description\n\n\n\n\n\n:::\n\n\n\n\n1430–1630: Stochastic character mapping\n\nShort description\n\n\n\n\n\n:::\n\n\n\nWednesday[October 1, 2025]\n\n\n\n\n\nIntro to State-dependent Speciation and Extinction (SSE) models\n\nShort description\n\n\n\n\n\nState-dependent Speciation and Extinction (SSE) models\n\nDisplay and embed PDFs\n\n\n\n\n\n\n\n\n\nThursday[October 2, 2025]\n\n\n\n\n\nIntro to Phylodynamics\n\nThis is about embedding R code\n\n\n\n\n\nModels in BEAST2\n\nSame as R but with Python\n\n\n\n\n\n\n\n\n\nFriday[October 3, 2025]\n\n\n\n\n\nAdvanced BEAST2 topics: BSSVS\n\nThis is about embedding R code\n\n\n\n\n\nModels in BEAST2\n\nSame as R but with Python\n\n\n\n\n\n\n\n \n\n\nHosted by:"
  },
  {
    "objectID": "topics/character_mapping/stochastic_mapping.html",
    "href": "topics/character_mapping/stochastic_mapping.html",
    "title": "Simulating stochasting character mappings",
    "section": "",
    "text": "This code simulates stochastic character mappings on a fixed phylogenetic tree. In the real world, we would be given a phylogeny with tip data (diets of finches, geographic location of influenza, etc.). The goal would be to estimate quantities like the number of changes, the timing of changes, whether one trait is ancestral to the rest, and so on. This would involve fitting models to estimate the stochastic rate matrix describing discrete state changes, as well as the root states.\nIn this code, we are going to start by exploring how we would interpret estimates. This involves simulating character mappings on the phylogeny using the true values of the Markov chain model, and our goal is to see if we can count the number of state changes, describe timing of changes, etc.\nOnce we have a feel for how the model works, we will then try to do the harder task of fitting it to data.\nClear out the console:\n\nrm(list=ls())\n\n# load in the package for stochastic character mapping:\nlibrary(phytools)\n\nLoading required package: ape\n\n\nLoading required package: maps\n\n# Set the number of stochastic character mappings to simulate:\nnsim = 1000\n\n# Create a tree: (could modify this to load in a tree as well)\ntree &lt;- pbtree(n=50, scale=1)\n\nSpecify a transition rate matrix for two states (A and B). In practice, we would want to estimate this from data. Let’s pretend we’ve done that step, and this can be taken as known without error:\n\nQ &lt;- matrix(c(-1,1,\n              1,-1),2,2)\nrownames(Q) &lt;- colnames(Q) &lt;- c(\"A\",\"B\")\n\nWe can scale down Q to have fewer transitions (for illustrative purposes)\n\nQ &lt;- Q/10\n\nSimulate tip states on the tree using our stochastic rate matrix Q. In practice, this would be observed in data, and in many instances we could assume it is observed without error. For our purposes here, we simulate tip states from the model:\n\ntip_states &lt;- sim.Mk(tree, Q)\n\nHow many of each state do we oberve?\n\ntable(tip_states)\n\ntip_states\n A  B \n 1 49 \n\n\nSimulate stochastic character maps nsim times using the tree, tip states, and our Q matrix: Note: don’t set model=Q, otherwise that just re-estimates Q. Need to specify Q=Q in the make.simmap call.\nWe simulate from the root to the tips. We have to specify an initial condition at the root:\n\nPi &lt;- c(.5,.5)\n\n# Run the sims!\nsims &lt;- make.simmap(tree, tip_states, Q=Q, pi=Pi, nsim=nsim)\n\nmake.simmap is sampling character histories conditioned on\nthe transition matrix\n\nQ =\n     A    B\nA -0.1  0.1\nB  0.1 -0.1\n(specified by the user);\nand (mean) root node prior probabilities\npi =\n  A   B \n0.5 0.5 \n\n\nDone.\n\n# Uncomment this to visualize the different character mappings:\n#par(mfrow=c(1,1))\n#for(i in 1:nsim){\n#   plot(sims[[i]])\n#   Sys.sleep(.0002)\n#}\n\n# Let's start by summarizing the number of mutations that happen across the whole tree:\n\ncounts &lt;- lapply(sims, countSimmap)\nnumMutations &lt;- sapply(counts, function(x) x$N)\ntransitions &lt;- lapply(counts, function(x)x$Tr)\ntransitions_AB &lt;- sapply(transitions, function(x) x[1,2])\ntransitions_BA &lt;- sapply(transitions, function(x) x[2,1])\n\nLet’s plot an example character mapped tree, and histograms of number of mutations:\n\nsim = sims[[1]]\n#  overall, and by type\npar(mfrow=c(2,2))\n## plot the character mapped tree\nsim$tip.label &lt;- paste(sim$tip.label, \"(\", tip_states, \")\", sep=\"\")\nplotSimmap(sim, fsize = 0.8)\n\nno colors provided. using the following legend:\n        A         B \n  \"black\" \"#DF536B\" \n\n## plottig make.simmap objects messes up margins, let's reset these:\npar(mar=c(5,4,4,1))\n## histogram of total mutations:\nhist(numMutations)\n## histogram of mutations A -&gt; B\nhist(transitions_AB)\n## histogram of mutations B -&gt; A\nhist(transitions_BA)"
  },
  {
    "objectID": "topics/character_mapping/stochastic_mapping.html#section",
    "href": "topics/character_mapping/stochastic_mapping.html#section",
    "title": "Simulating stochasting character mappings",
    "section": "1.",
    "text": "1.\nTry changing the initial condition at the root (Pi, also called the “root prior”) to see how results change"
  },
  {
    "objectID": "topics/character_mapping/stochastic_mapping.html#section-1",
    "href": "topics/character_mapping/stochastic_mapping.html#section-1",
    "title": "Simulating stochasting character mappings",
    "section": "2.",
    "text": "2.\nLook at the logL values in the sims. What do you think that describes? In particular, do you think the reported logL is P(tip data | Q), or P(tip data, character mapping | Q)?"
  },
  {
    "objectID": "topics/character_mapping/stochastic_mapping.html#a.",
    "href": "topics/character_mapping/stochastic_mapping.html#a.",
    "title": "Simulating stochasting character mappings",
    "section": "2.a.",
    "text": "2.a.\nCreate a new sims list, replacing Q with jitter(Q). What do you notice about the logL values?"
  },
  {
    "objectID": "topics/character_mapping/stochastic_mapping.html#section-2",
    "href": "topics/character_mapping/stochastic_mapping.html#section-2",
    "title": "Simulating stochasting character mappings",
    "section": "3.",
    "text": "3.\nIn light of the previous questions, can you figure out what the form of the log-likelihood is for make.simmap? (is it actually a likelihood, or is it a conditional likelihood?) That is, do you think the form of the log-likelihood is P(tip data | Q) or P(tip data | Q, Pi) ?"
  },
  {
    "objectID": "topics/character_mapping/stochastic_mapping.html#section-3",
    "href": "topics/character_mapping/stochastic_mapping.html#section-3",
    "title": "Simulating stochasting character mappings",
    "section": "4.",
    "text": "4.\nCalculate the log-likelihood of the tip data on the tree under the assumed Q matrix. Compare the log-likelihood reported from ace with the log-likelihood returned by make.simmap. What do you notice?"
  },
  {
    "objectID": "topics/character_mapping/stochastic_mapping.html#section-4",
    "href": "topics/character_mapping/stochastic_mapping.html#section-4",
    "title": "Simulating stochasting character mappings",
    "section": "5.",
    "text": "5.\nDo ace and make.simmap use the same log-likelihood? If not, what is the key difference? Use ?ace and ?make.simmap in your investigation."
  },
  {
    "objectID": "topics/ancestral_character_estimation/nucleotide_models.html",
    "href": "topics/ancestral_character_estimation/nucleotide_models.html",
    "title": "1. Basic Markov chains",
    "section": "",
    "text": "rm(list=ls())\nlibrary(ape)\nlibrary(expm) # matrix exponential\n\nLoading required package: Matrix\n\n\n\nAttaching package: 'expm'\n\n\nThe following object is masked from 'package:Matrix':\n\n    expm\n\n\nThe following object is masked from 'package:ape':\n\n    balance\nThis code simulates output from the ace function. We will first try to grasp how the model behaves before we we try fitting it to data.\nAncestral character estimation methods can be based on a variety of approaches, but we will consider Markov chains superimposed on phylogenies. In the accompanying code to this we will learn how to fit these models using Maximum Likelihood, but for now we focus on simulating Markov chains on trees to understand how the models work."
  },
  {
    "objectID": "topics/ancestral_character_estimation/nucleotide_models.html#section",
    "href": "topics/ancestral_character_estimation/nucleotide_models.html#section",
    "title": "1. Basic Markov chains",
    "section": "1.",
    "text": "1.\nWrite down a 4-state Markov model corresponding to A, C, T, and G in DNA. Evaluate the transition probabilities as above (hint: the matrix exponential can be calculated in R using the expm function from the package of the same name. Feel free to assume whatever constraints on parameters you like (or none at all)."
  },
  {
    "objectID": "topics/ancestral_character_estimation/nucleotide_models.html#section-1",
    "href": "topics/ancestral_character_estimation/nucleotide_models.html#section-1",
    "title": "1. Basic Markov chains",
    "section": "2.",
    "text": "2.\nThe Jukes-Cantor model is the simplest nucleotide substitution model. By assumption, the equilibrium probabilities of each nucleotide are equal, and the transition rates between states are likewise all equal. What is the generator for this process? Write a function to describe transition probabilities as a function of time. (Hint: how many parameters will your generator have if all transitions between states occur at equal rates?)"
  },
  {
    "objectID": "topics/ancestral_character_estimation/nucleotide_models.html#section-2",
    "href": "topics/ancestral_character_estimation/nucleotide_models.html#section-2",
    "title": "1. Basic Markov chains",
    "section": "3.",
    "text": "3.\nThe K80 (Kimura, 1980) model elaborates on the Jukes-Cantor model by allowing substitutions within pyrimidines (C,T) and within purines (A, G) to occur at a different rate than “transversions” between pyrimidines and purines. In biology, substitutions between two purines or between two pyrimidines are called “transitions” (but in Markov chains, mathematicians refer to all state changes as transitions – confusing). Assuming that transitions (in the biological sense of the word) occur at the same rate regardless of whether the nucleotides are purines or pyrimidines, and assuming that transversions in either direction occur at the same rate, write the generator for the Markov process and write a function that calculates transition probabilities as a function of time."
  },
  {
    "objectID": "topics/sse_models/fit_bd.html",
    "href": "topics/sse_models/fit_bd.html",
    "title": "Estimating parameters of basic birth-death models",
    "section": "",
    "text": "Estimating parameters of basic birth-death models\nrm(list=ls())\n\n\nNow that we have some familiarity with the behavior of the birth-death\n\n\nmodel, we will try to use the model for parameter inference,\n\n\ni.e. model fitting.\n\n\nModel fitting just consists of selecting parameters of the model so\n\n\nthat the simulated outputs match our data as closely as possible.\n\n\nThe dumbest way imaginable is to use the “eyeball test”. The most\n\n\nsophisticated approach is to use likelihoods. Methods like synthetic\n\n\nlikelihood and approximate Bayesian computations (ABC) fall somewhere\n\n\nin between.\n\n\nFor this set of examples and exercises, we will just adopt a frequentist\n\n\napproach to statistical inference.\n\n\nThe diversitree package has a convenient class of functions that can be\n\n\nused to define likelihood functions for different models. We will\n\n\nstart with the simplest case - the birth death model.\n\n\nExample 1: Benchmarking from simulations\n\n\nsimulate a list of bd trees here\ntree &lt;- tree.bd(c(lambda=5,mu=0), max.taxa = 20)\nloglik &lt;- make.bd(tree)\n\n\nthe make.bd function is a scalar function of two variables\n\n\nof the form loglik = loglik(c(lambda,mu))\n\n\nLet’s visualize the likelihood surface one parameter at a time\n\n\n(holding the other parameter at the true value):\nloglik_lambda &lt;- function(lambda) loglik(c(lambda,0)) loglik_mu &lt;- function(mu) loglik(c(1,mu))\nlambdavals &lt;- exp( seq(-3,3,length=30)) muvals &lt;- exp( seq(-6,2,length=30)) loglik_lambda_vals &lt;- sapply(lambdavals, loglik_lambda) loglik_mu_vals &lt;- sapply(muvals, loglik_mu)\nloglik_max &lt;- max(c(loglik_lambda_vals, loglik_mu_vals))\npar(mfrow=c(2,1)) plot(lambdavals, loglik_lambda_vals, ylim=c(loglik_max-10,loglik_max+2)) plot(muvals, loglik_mu_vals, ylim=c(loglik_max-10,loglik_max+2))\n\n\nThe maximum of the log-likelihood function roughly coincides with the\n\n\nparameters we used. How variable is this? Let’s simulate more\n\n\ntrees:\ntreelist &lt;- trees(c(lambda=5,mu=0), type=c(“bd”), n=100, max.taxa=20)\n\n\nmake a log-likelihood function for each tree:\nlogliklist &lt;- lapply(treelist, make.bd )\nloglik_lambda_list &lt;- lapply(logliklist, function(x){ function(lambda) x(c(lambda,0)) })\nloglik_mu_list &lt;- lapply(logliklist, function(x){ function(mu) x(c(mu,0)) })\nlambdavals &lt;- exp( seq(-2,2,length=30)) muvals &lt;- exp( seq(-6,2,length=30))\nloglik_lambda_list_vals &lt;- sapply(loglik_lambda_list, function(x){sapply(lambdavals, x)})\nloglik_mu_list_vals &lt;- sapply(loglik_mu_list, function(x){sapply(muvals, x)})\nloglik_max &lt;- max(c(loglik_lambda_list_vals,loglik_mu_list_vals)) loglik_min &lt;- min(c(loglik_lambda_list_vals,loglik_mu_list_vals))\npar(mfrow=c(2,1)) plot(lambdavals, loglik_lambda_list_vals[,1]/abs(max(loglik_lambda_list_vals[,1]))) for(i in 2:100){ lines(lambdavals, loglik_lambda_list_vals[,i]/abs(max(loglik_lambda_list_vals[,i]))) }\nplot(muvals, loglik_mu_list_vals[,1]/abs(max(loglik_mu_list_vals[,1]))) for(i in 2:100){ lines(muvals, loglik_mu_list_vals[,i]/abs(max(loglik_mu_list_vals[,i]))) }\n\n\nSo, most of these have a maximum in the vicinity of the true parameter values that we\n\n\nsuppied, but not all.\n\n\nThe “Maximum Likelihood Estimates” are the values of (lambda,mu) where the likelihood function is\n\n\nmaximized. What does the distribution of MLEs look like for this set of trees?\nmles &lt;- lapply(logliklist, function(x){find.mle(x, c(1,0), method=‘subplex’)})\nmles_pars &lt;- t(sapply(mles, function(x) x$par))\npar(mfrow=c(1,2)) hist(mles_pars[,1],main=’‘, xlab=bquote(hat(lambda))) hist(mles_pars[,2],main=’’, xlab=bquote(hat(mu)))\n\n\nRemember that the true value of mu we used was mu=0. A lot of the models suggest values of\n\n\nmu &gt; 0, which is interesting. This tells us that, in practice, we will probably not\n\n\nbe able to reliably estimate mu when it is close to zero but positive.\n\n\nWe can frame a hypothesis test. Null hypothesis: mu=0. Alternative hypothesis: mu &gt; 0.\n\n\nSupposing we wish to keep false-positives at 5% or less, we could propose the statistical\n\n\ntest that we reject the null hypothesis if our estimate of mu is at the 95-th percentile or greater\n\n\nof this “null” distribution. In our case, this critical value of mu would be approximately\nmu_critical &lt;- quantile(mles_pars[,‘mu’], 0.95)\n\n\nSo in the future, if we estimate a value of mu greater than mu_critical, and we say “this appears\n\n\nsignificantly different from zero, therefore we reject the null hypothesis”, we will be making a\n\n\ntype 1 error (“false-positive”) less than 5% of the time. A 1/20 chance of a mistake is reasonable\n\n\nin some circumstances, but less so in others.\n\n\n\n\n\nExercises:\n\n\n\n\n\n1. Suppose we want a more stringent statistical test for the previous example. What is the critical\n\n\nvalue of mu corresponding to a 1% chance of comitting a Type 1 error?\n\n\n2. Modify the previous example to see how things change for a different value of lambda. Try lambda = 5.\n\n\nDoes the critical value of mu change?\n\n\n3. The Generalized Likelihood Ratio Test: another way to assess whether mu is significantly different from\n\n\nzero is to fit two versions of the log-Likelihood function: the one we already did, and a constrained\n\n\nversion of the model with the constraint mu=0 hard-coded in (so that we just estimate lambda). The\n\n\nmodel with more parameters will always fit the data better, but it may not fit the data “that much”\n\n\nbetter. The GLT looks a log(ratio of likelihoods) = difference(log-Likelihoods) to produce a test\n\n\nstatistic (also, rather annoyingly in this case, called lambda). Use constrain(loglik, mu ~ 0) to\n\n\ncreate the constrained log-likelihood functions, and fit them to obtain new estimates for lambda.\n\n\nUse Wikipedia, Google, or your favorite (work-safe) AI companion to help you formulate GLT test\n\n\nstatistics and assess significant departues from the null hypothesis mu=0. Do the results of this\n\n\nstatistical test match with those from earlier? If not, why not?\n\n\n(Hint: the GLR also makes an asymptotic approximation. What is that approximation, and under\n\n\nwhat situations would it apply here?)\n\n\n4. Consider a different null hypothesis: lambda &gt; mu. Develop a test statistic for this hypothesis, and\n\n\nidentify critical values of your test statistic for 95% and 99% confidence regions. (Simulate large\n\n\nnumbers of trees to obtain MLEs; don’t worry about GLR tests unless you want to).\n\n\n5. If your simulation produced trees with estimated values of lambda &lt; mu, plot these trees and comment\n\n\non any features they exhibit that stand out to you. If your simulation did not produce trees with\n\n\nMLEs having lambda &lt; mu, simulate as necessary until you find some.\n\n\n6. The find.mle function uses a variety of numerical optimization algorithms to find MLEs. There is also a\n\n\nfunction called “mcmc”. Use this function with nsteps=1000 and w=c(2,1). Plot loglikelihood (“p”)\n\n\nagainst parameters to visualize profile log-likelihoods, and also plot lambda against mu. Comment\n\n\non what you see, and discuss implications of correlations between lambda and mu. (Note: there are\n\n\nother mcmc routines besides this one in diversitree. If you have a favorit method, feel free to\n\n\nuse it.)\n\n\n7. The previous exercises and examples used the max.taxa argument to condition on trees of a particular\n\n\nsize. Flip a coin ( rbinom(1,1,0.5)). If it comes up heads (=1), change max.taxa to a different number\n\n\nand repeat Exercises 1-6. If it comes up tails (=0), replace max.taxa with max.t to simulate trees\n\n\nfor a fixed amount of time (with variable numbers of taxa), and then repeat Exercises 1-6. (Caution:\n\n\ninjudicious choices of lambda and max.t can make your computer explode. Ctrl + c is useful (on Mac,\n\n\nanyway) for cancelling calculations in the Terminal.)"
  }
]